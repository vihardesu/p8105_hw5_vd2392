---
title: "p8105_hw5_vd2392.Rmd"
output: github_document
---

## Setup 

##### General
```{r general_setup}
knitr::opts_chunk$set(
  echo = TRUE,
  include = TRUE,
  message = FALSE,
  warning = FALSE
)
```

##### Visualizations
```{r visualiztion_setup}
knitr::opts_chunk$set(fig.width = 6,
                      fig.asp = .6,
                      out.width = "90%")
```

##### Installations
```{r installations}
library(tidyverse)
library(ggridges)
library(patchwork)
library(readxl)
```

## Problem 1

This dataset contains 52,000 criminal homicides over the past decade in 50 of the largest American cities. Among the variables of interest include location of the killing, whether an arrest was made and, in most cases, basic demographic information of each victim.

```{r p1_data}
homicide_df =
  read_csv("data/homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>%
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa_AL")

aggregate_df =
  homicide_df %>%
  group_by(city_state) %>%
  summarize(hom_total = n(),
            hom_unsolved = sum(resolved == "unsolved"))
```

#### Confidence Interval for Baltimore Data
```{r p1_test}
prop_test = prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)
) %>%
  broom::tidy()

knitr::kable(prop_test, "simple", caption = "Data: Homicide Data")
```

#### Confidence Interval for All Cities
```{r p1_ci}
results_df =
  aggregate_df %>%
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~ prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~ broom::tidy(.x))
  ) %>%
  select(-prop_tests) %>%
  unnest(tidy_tests) %>%
  select(city_state, estimate, conf.low, conf.high)

knitr::kable(head(results_df), "simple", caption = "Data: Homicide Data")
```

#### Confidence Intervals Comparisons of Unsolved Homicides in 50 large US Cities
```{r p1_results}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(
    angle = 90,
    vjust = 0.5,
    hjust = 1
  )) +
  ggtitle("CI Intervals for Unsolved Homicides in 50 large US Cities") +
  labs(y = "Estimate of Unsolved / Total Homicides", x = "City_State")
```

## Problem 2

#### List of File  Names in RCT Data
```{r p2_files}
data_path = "data/rct_data/"

rct_files =
  tibble(file = list.files(data_path),)

knitr::kable(head(rct_files), "simple", caption = "Source: RCT Data")
```

#### Extracted RCT Data
```{r p2_extracted_files}
extract = function(path) {
  data = read_csv(path) %>%
    janitor::clean_names()
  data
}

consolidated_rct = rct_files %>%
  mutate(path = str_c(data_path, file),
         data = as.vector(map_dfr(path, extract)))
```

#### Preview of Extracted File Data 
This data is nested inside `consolidated_rct` data frame.
```{r p2_preview_one}

knitr::kable(head(consolidated_rct$data), "simple", caption = "Source: RCT Data")

```

#### Preview of Tidied RCT Data
```{r p2_cleanup}

rct = consolidated_rct %>% {
  bind_cols(select(., file:path), bind_rows(!!!.$data))
}

rct = rct  %>%
  mutate(
    subject_id = case_when(
      substr(file, 0, 3) == "con" ~ paste("Control", substr(file, 5, 6), sep = "_"),
      substr(file, 0, 3) == "exp" ~ paste("Experimental", substr(file, 5, 6), sep = "_")
    ),
    treatment_arm = case_when(
      substr(file, 0, 3) == "con" ~ "Control",
      substr(file, 0, 3) == "exp" ~ "Experimental"
    )
  ) %>%
  select(treatment_arm, subject_id, week_1:week_8) %>%
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "result",
    names_prefix = "week_"
  ) %>%
  mutate(week = as.numeric(week))
```

#### Aggregate and Tidied RCT Data
```{r p2_preview_2}
knitr::kable(head(rct), "simple", caption = "Source: RCT Data")
```

#### Outcomes: Control vs. Experimental 

As we can see from the plot below, this particular longitudinal study included a control arm and an experimental arm that was measured over a specific variable over 8 weeks. The experimental group showed positive linear relationship over 8 weeks with respect to the outcome of interest. It seems as though the control group trended towards no change. This data has to be tested for statistical significance before a real conclusion can be made. 

```{r p2_analysis}
ggplot(data = rct,
       aes(
         x = week,
         y = result,
         group = subject_id,
         color = treatment_arm
       )) +
  geom_line(data = rct) +
  ggtitle("Outcomes over 8 Weeks - Experiment vs. Control") +
  labs(y = "Outcome", x = "Week Number", color = "Treatment Arm")
```

## Problem 3

#### Simulation of mu = 0
```{r p3_simulation_one}
n = 30
sigma = 5
alpha = 0.05
mu = 0
trials = 5000

simulation = function(n = n,
                      mu = mu,
                      sigma = sigma,
                      alpha = alpha) {
  data = tibble(x = rnorm(n, mean = mu, sd = sigma))
  data %>%
    summarize(
      mu_hat = mean(x),
      p.value = t.test(x, mu = mu, conf.level = 1 - alpha) %>%
        broom::tidy() %>%
        select(p.value)
    ) %>%
    unnest(p.value) %>%
    mutate(reject_null = as.logical(p.value <= alpha))
}

mu_0_results = rerun(trials, simulation(n, mu, sigma, alpha)) %>% bind_rows
```

#### Experiment, mu = 0
```{r p3_simulation_preview}
knitr::kable(head(mu_0_results), "simple", caption = "Source: Experiment")
```

#### Experiment, mu = 0:6
```{r p3_simulation_abstraction}

output = vector("list", length = 7)

for (i in 1:7) {
  output[[i]] = rerun(trials, simulation(n, i - 1, sigma, alpha)) %>%
    bind_rows
}

sim_results =
  tibble(true_mu = c(0, 1, 2, 3, 4, 5, 6)) %>%
  mutate(estimate_dfs = map(output, bind_rows)) %>%
  unnest(estimate_dfs)
```

#### Experiment with Various True Mu Values
```{r p3_abstraction_preview}
knitr::kable(head(sim_results), "simple", caption = "Source: Experiment")
```

#### Power of Two-Sided T-Test for Various True Mu's

A t-test's effect size indicates whether or not the difference between two groups' averages is large enough to have practical meaning, whether or not it is statistically significant. The probability that a false null hypothesis is rejected is referred to as power. In our experiment, as True Mu changes, it appears that the the power is largely unchanged. 

```{r p3_plot_one}
sim_results %>%
  mutate(true_mu = as.factor(true_mu)) %>%
  group_by(true_mu) %>%
  summarize(proportion = sum(reject_null) / trials) %>%
  ggplot(aes(x = true_mu, y = proportion, fill = true_mu)) +
  geom_bar(stat = "identity") +
  geom_text(
    aes(label = proportion),
    vjust = 1.6,
    color = "white",
    size = 3.5
  ) +
  ggtitle("Power of Two-Sided T-Test for Various True Mu's") +
  labs(y = "Power", x = "True Mu", color = "True Mu")
```

#### Sample Mu's in Two-Sided T-Test for Various True Mu's
```{r p3_plot_two}
all = sim_results %>%
  mutate(true_mu = str_c("n = ", true_mu),
         true_mu = fct_inorder(true_mu)) %>%
  ggplot(aes(x
             = true_mu, y = mu_hat, fill = true_mu)) +
  geom_violin() +
  ggtitle("Distribution of Sample Mu's in Two-Sided T-Test for Various True Mu's") +
  labs(y = "Distributions of Sample Mu", x = "True Mu", color = "True Mu")
```

#### Rejected Sample Mu's in Two-Sided T-Test for Various True Mu's
```{r p3_plot_three}
rejected = sim_results %>%
  filter(reject_null == TRUE) %>%
  mutate(true_mu = str_c("n = ", true_mu),
         true_mu = fct_inorder(true_mu)) %>%
  ggplot(aes(x = true_mu, y = mu_hat, fill = true_mu)) +
  geom_violin() +
  ggtitle("Distribution of Rejected Sample Mu's in Two-Sided T-Test for Various True Mu's") +
  labs(y = "Distributions of Sample Mu", x = "True Mu", color = "True Mu")
```

#### Comparison of Accepted and Rejected Experiment Distributions

The sample mu's that were rejected trended away from the True Mu, typically distributed on either poll of the distribution for each True Mu. This is expected as the power of our experiment represents the probability a false null hypothesis is rejected at our significance level of 0.05. These rejected sample means yield statistically unlikely events outside our 95% confidence interval of our normal distributions.

```{r p3_plot_visualization_one}
all
```

```{r p3_plot_visualization_two}
rejected
```


